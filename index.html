<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Brian Park</title>

    <meta name="author" content="Brian Park">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
    <link rel="manifest" href="/images/site.webmanifest">
</head>

<body>
<table style="width:100%;max-width:1050px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p style="text-align:center">
                            <name>Brian Seonggeun Park</name>
                        </p>
                        <p>I am an undergraduate student studying Computer Science and Engineering at <a href="https://www.cs.ucla.edu/">UCLA</a> where I
                            am a member of the <a href="https://structures.computer/">Structures-Computer Interaction
                                (SCI) Lab</a>.
                            My advisors are Professors <a href="http://www.khalidjawed.com/">M. Khalid Jawed</a> and <a
                                    href="https://www.jsjoo.com/">Jungseock Joo</a>.
                        </p>
                        <p>
                            My research focus pertains to the general intersection of robotics, graphics, and deep
                            learning. More specifically, I am interested in tackling the sim2real gap by leveraging
                            physics-based simulations to teach useful and transferable skills to robots through
                            data-driven methods.
                        </p>
                        <p>
                            <style>
                                ol {
                                    /*list-style:none;*/
                                    padding-left: 22px;
                                }
                            </style>
                            Overall, my research can be roughly categorized into developing:
                        <ol>
                            <li>&nbsp physically accurate simulators for deformable materials and soft robots,
                            </li>
                            <li> &nbsp sim2real solutions for robotic manipulation of deformable materials,</li>
                            <li> &nbsp robust perception algorithms for detecting deformable materials, and</li>
                            <li> &nbsp end-to-end robotic pipelines for efficient 3D reconstruction.</li>
                        </ol>
                        </p>
                        <p style="text-align:center">
                            <a href="mailto:asjchoi@g.ucla.com">Email</a> &nbsp/&nbsp
                            <a href="data/CV.pdf">CV</a> &nbsp/&nbsp
                            <a href="https://www.linkedin.com/in/andrew-choi-42a062169/">LinkedIn</a> &nbsp/&nbsp
                            <a href="https://scholar.google.com/citations?user=chiMYfwAAAAJ&hl=en">Google Scholar</a>
                            &nbsp/&nbsp
                            <a href="https://github.com/QuantuMope/">GitHub</a>
                        </p>
                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="images/profile_pic.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                                                              src="images/profile_pic_circle.png" class="hoverZoomLink"></a>
                    </td>
                </tr>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Preprints</heading>
                    </td>
                </tr>
                </tbody>
            </table>


            <table style="width:100%;border:20px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>


                <tr>
                    <td style="padding-left:20px;width:10%;vertical-align:middle">
                        <div class="one">
                            <img src='images/folding_iso.gif' width="180">
                        </div>
                    </td>
                    <td style="padding-left:80px;padding-top:35px;width:90%;vertical-align:middle">
                        <a href="https://arxiv.org/pdf/2302.09444.pdf">
                            <papertitle>Deep Learning of Force Manifolds from the Simulated Physics of Robotic Paper
                                Folding
                            </papertitle>
                        </a>
                        <br>
                        <a href="https://www.linkedin.com/in/dezhong-tong-5b6b85224/">Dezhong Tong</a><strong>*</strong>,
                        <strong>Andrew Choi*</strong>,
                        <a href="https://web.cs.ucla.edu/~dt/">Demetri Terzopoulos</a>,
                        <a href="https://www.jsjoo.com/">Jungseock Joo</a>,
                        <a href="https://www.khalidjawed.com/">M. Khalid Jawed</a>

                        <br>
                        <em>submitted to IEEE Transactions on Automation Science and Engineering (T-ASE)</em>, 2023
                        <span class="right">(<strong>*</strong> equal contribution)</span>
                        <br>
                        <a href="https://www.youtube.com/watch?v=sRpjZhPZSx0&t=6s">Video</a>
                        /
                        <a href="https://meetings.aps.org/Meeting/MAR23/Session/Q10.5">Oral Presentation</a>
                        /
                        <a href="https://techxplore.com/news/2023-01-method-enable-robotic-paper-based.html">News
                            Coverage</a>
                        <p></p>
                        <p>
                            End-to-end pipeline for full sim2real robotic paper folding.
                            Neural force manifolds are learned from physical simulation and are used to generate optimal
                            folding trajectories.
                            Scaling analysis is used to obtain a generalizable control policy with respect to material
                            and
                            geometric parameters.
                        </p>
                    </td>
                </tr>


                <tr>
                    <td style="padding:20px;width:10%;vertical-align:middle">
                        <div class="one">
                            <img src='images/deployment.gif' width="180">
                        </div>
                    </td>
                    <td style="padding-left:80px;padding-top:35px;width:90%;vertical-align:middle">
                        <a href="https://arxiv.org/pdf/2303.02574.pdf">
                            <papertitle>Sim2Real Physically Informed Neural Controllers <br> for Robotic Deployment of
                                Deformable Linear Objects
                            </papertitle>
                        </a>
                        <br>
                        <a href="https://www.linkedin.com/in/dezhong-tong-5b6b85224/">Dezhong Tong</a>,
                        <strong>Andrew Choi</strong>,
                        <a href="https://www.researchgate.net/profile/Longhui-Qin">Longhui Qin</a>,
                        <a href="https://scholar.google.com/citations?user=KbEBKIMAAAAJ&hl=en">Weicheng Huang</a>,
                        <a href="https://www.khalidjawed.com/">M. Khalid Jawed</a>
                        <br>
                        <em>submitted to International Journal of Robotics Research (IJRR)</em>, 2023
                        <br>
                        <p></p>
                        <p>
                            End-to-end pipeline for full sim2real robotic DLO deployment.
                            Physical simulations are used to train a neural controller capable of deploying rods along a
                            prescribed pattern.
                            Scaling analysis is used to obtain a generalizable control policy with respect to material
                            and geometric parameters.

                        </p>
                    </td>
                </tr>


                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                    <tr>
                        <td style="padding:20px;width:100%;vertical-align:middle">
                            <heading>Publications</heading>
                        </td>
                    </tr>
                    </tbody>
                </table>
                <table style="width:100%;border:20px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>


                    <tr>
                        <td style="padding-left:20px;padding-top:20px;padding-bottom:40px;width:10%;vertical-align:middle">
                            <div class="one">
                                <img src='images/mbest_stacked.gif' width="180">
                            </div>
                        </td>
                        <td style="padding-left:80px;padding-top:35px;width:90%;vertical-align:middle">
                            <a href="https://arxiv.org/pdf/2302.09444.pdf">
                                <papertitle>mBEST: Realtime Deformable Linear Object Detection <br> Through Minimal
                                    Bending
                                    Energy Skeleton Pixel Traversals
                                </papertitle>
                            </a>
                            <br>
                            <strong>Andrew Choi</strong>,
                            <a href="https://www.linkedin.com/in/dezhong-tong-5b6b85224/">Dezhong Tong</a>,
                            <a href="https://www.linkedin.com/in/briannparkk/">Brian Park</a>,
                            <a href="https://web.cs.ucla.edu/~dt/">Demetri Terzopoulos</a>,
                            <a href="https://www.jsjoo.com/">Jungseock Joo</a>,
                            <a href="https://www.khalidjawed.com/">M. Khalid Jawed</a>
                            <br>
                            <em>IEEE Robotics and Automation Letters (RA-L)</em>, 2023
                            <br>
                            <a href="https://github.com/StructuresComp/mBEST">Source Code & Data</a>
                            /
                            <a href="https://www.youtube.com/watch?v=q84I9i0DOK4">Video</a>
                            <p></p>
                            <p>
                                Robust and rapid instance segmentation of DLOs via skeleton pixel traversals.
                                Segmentations are generated on topologically corrected skeleton structures with
                                intersections handled
                                by the simple and physically insightful optimization objective of minimizing cumulative
                                bending energy.

                            </p>
                        </td>
                    </tr>


                    <tr>
                        <td style="padding-left:20px;width:10%;vertical-align:middle">
                            <div class="one">
                                <img src='images/imv_v2.gif' width="180">
                            </div>
                        </td>
                        <td style="padding-left:80px;padding-top:30px;width:90%;vertical-align:middle">
                            <a href="https://arxiv.org/pdf/2205.10309.pdf">
                                <papertitle>A Fully Implicit Method for Robust Frictional Contact Handling in Elastic
                                    Rods
                                </papertitle>
                            </a>
                            <br>
                            <a href="https://www.linkedin.com/in/dezhong-tong-5b6b85224/">Dezhong
                                Tong</a><strong>*</strong>,
                            <strong>Andrew Choi*</strong>,
                            <a href="https://www.jsjoo.com/">Jungseock Joo</a>,
                            <a href="https://www.khalidjawed.com/">M. Khalid Jawed</a>
                            <!--                        (<strong>*</strong> equal contribution)-->
                            <br>
                            <em>Extreme Mechanics Letters (EML)</em>, 2023
                            <span class="right">(<strong>*</strong> equal contribution)</span>
                            <br>
                            <a href="https://github.com/StructuresComp/rod-contact-sim">Source Code</a>
                            /
                            <a href="https://www.youtube.com/watch?v=g0rlCFfWJ8U&t=26s">Video</a>
                            /
                            <a href="https://meetings.aps.org/Meeting/MAR23/Session/K07.4">Oral Presentation</a>
                            <p></p>
                            <p>
                                Fully implicit frictional contact method for simulation of slender elastic rods.
                                Enforces non-penetration and capable of reproducing sticking and sliding phenomena.
                                Case study for flagella bundling in viscous fluid shown.
                            </p>
                        </td>
                    </tr>


                    <tr>
                        <td style="padding-left:20px;padding-top:20px;padding-bottom:60px;width:10%;vertical-align:middle">
                            <div class="one">
                                <img src='images/buckling2.gif' width="180">
                            </div>
                        </td>
                        <td style="padding-left:80px;padding-top:15px;width:90%;vertical-align:middle">
                            <a href="https://asmedigitalcollection.asme.org/appliedmechanics/article-abstract/90/4/041008/1154422/Snap-Buckling-in-Overhand-Knots">
                                <papertitle>Snap Buckling in Overhand Knots</papertitle>
                            </a>
                            <br>
                            <a href="https://www.linkedin.com/in/dezhong-tong-5b6b85224/">Dezhong Tong</a>,
                            <strong>Andrew Choi</strong>,
                            <a href="https://www.jsjoo.com/">Jungseock Joo</a>,
                            <a href="https://www.andyborum.com/">Andy Borum</a>,
                            <a href="https://www.khalidjawed.com/">M. Khalid Jawed</a>
                            <br>
                            <em>Journal of Applied Mechanics (JAM)</em>, 2022
                            <br>
                            <a href="https://github.com/StructuresComp/snap-buckling-knots">Source Code</a>
                            /
                            <a href="https://www.youtube.com/watch?v=g0rlCFfWJ8U&t=26s">Video</a>
                            <p></p>
                            <p>
                                Study of the snap buckling process of overhand knots.
                                Discrete differential geometry based simulations and tabletop experiments are used to
                                explore the onset of buckling as a function of topology, geometry, and friction.
                            </p>
                        </td>
                    </tr>

                    <tr>
                        <td style="padding-left:10px;padding-top:10px;width:10%;vertical-align:middle">
                            <div class="one">
                                <img src='images/pmp.gif' width="200">
                            </div>
                        </td>
                        <td style="padding-left:80px;padding-top:0px;width:75%;vertical-align:middle">
                            <a href="https://arxiv.org/pdf/2203.00156.pdf">
                                <papertitle>Preemptive Motion Planning for Human-to-Robot Indirect Placement Handovers
                                </papertitle>
                            </a>
                            <br>
                            <strong>Andrew Choi</strong>,
                            <a href="https://www.khalidjawed.com/">M. Khalid Jawed</a>,
                            <a href="https://www.jsjoo.com/">Jungseock Joo</a>
                            <br>
                            <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2022
                            <br>
                            <a href="https://pmp-human-to-robot.github.io/">Project Page</a>
                            /
                            <a href="https://www.youtube.com/watch?v=O1oz8yw_Er0&t=6s">Video</a>
                            <p></p>
                            <p>
                                Preemptive motion planning via human object placement prediction using human pose and
                                gaze
                                as input.
                                Rapidly outperforms traditional wait-and-react methods for human-to-robot pick-and-place
                                operations.
                            </p>
                        </td>
                    </tr>

                    <tr>
                        <td style="padding-left:20px;width:10%;vertical-align:middle">
                            <div class="one">
                                <img src='images/vessel_seg.gif' width="180">
                            </div>
                        </td>
                        <td style="padding-left:80px;padding-top:35px;width:90%;vertical-align:middle">
                            <a href="https://openaccess.thecvf.com/content/WACV2022/papers/Vepa_Weakly-Supervised_Convolutional_Neural_Networks_for_Vessel_Segmentation_in_Cerebral_Angiography_WACV_2022_paper.pdf">
                                <papertitle>Weakly-Supervised Convolutional Neural Networks <br> for Vessel Segmentation
                                    in
                                    Cerebral Angiography
                                </papertitle>
                            </a>
                            <br>
                            <a href="https://www.linkedin.com/in/arvind-vepa-4b759323/">Arvind Vepa</a>,
                            <strong>Andrew Choi</strong>,
                            <a href="https://web.cs.ucla.edu/~noornk/">Noor Nakhaei</a>,
                            <a href="https://www.math.ucla.edu/~wlee/">Wonjun Lee</a>,
                            <em>et al.</em>
                            <br>
                            <em>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>, 2022
                            <br>
                            <p></p>
                            <p>
                                Weak supervision approaches for automated vessel segmentation.
                                Utilizes active contour models to generate weak labels and introduces low-cost
                                human-in-the-loop strategies that drastically reduce labelling cost while maintaining
                                segmentation accuracy.
                            </p>
                        </td>
                    </tr>


                    <tr>
                        <td style="padding-left:20px;width:10%;vertical-align:middle">
                            <!--                    <td style="padding:20px;width:25%;vertical-align:middle">-->
                            <div class="one">
                                <img src='images/imc_v1.gif' width="180">
                            </div>
                        </td>
                        <td style="padding-left:80px;padding-top:40px;width:90%;vertical-align:middle">
                            <a href="https://asmedigitalcollection.asme.org/appliedmechanics/article/88/5/051010/1099667">
                                <papertitle>Implicit Contact Model for Discrete Elastic Rods in Knot Tying</papertitle>
                            </a>
                            <br>
                            <strong>Andrew Choi</strong>,
                            <a href="https://www.linkedin.com/in/dezhong-tong-5b6b85224/">Dezhong Tong</a>,
                            <a href="https://www.khalidjawed.com/">M. Khalid Jawed</a>,
                            <a href="https://www.jsjoo.com/">Jungseock Joo</a>
                            <br>
                            <em>Journal of Applied Mechanics (JAM)</em>, 2021
                            <br>
                            <a href="https://github.com/QuantuMope/imc-der">Source Code</a>
                            /
                            <a href="https://www.youtube.com/watch?v=yq4-m0G0D4g">Video</a>
                            <p></p>
                            <p>
                                An implicit contact model for slender elastic rod simulation capable of enforcing
                                non-penetration via smooth penalty energy and edge-to-edge minimum distance formulation.
                                Sliding friction is handled semi-explicitly.
                                Extensive physical validation through knot tying case study.
                            </p>
                        </td>
                    </tr>

                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                        <tr>
                            <td>
                                <heading>Misc Robotics Software</heading>
                            </td>
                        </tr>
                        </tbody>
                    </table>
                    <table width="100%" align="center" border="0" cellpadding="20">
                        <tbody>

                        <tr>
                            <td style="padding-left:20px;width:10%;vertical-align:middle">
                                <!--                    <td style="padding:20px;width:25%;vertical-align:middle">-->
                                <div class="one">
                                    <img src='images/4dof.png' width="180">
                                </div>
                            </td>
                            <td style="padding-left:80px;width:90%;vertical-align:middle">
                                <a href="https://github.com/QuantuMope/handeye-4dof">
                                    <papertitle>Handeye Calibration Module for 4DOF Manipulators using Dual Quaternions
                                    </papertitle>
                                </a>
                                <br>
                                <em>GitHub Repository</em>, 2021
                                <br>
                                <a href="https://github.com/QuantuMope/handeye-4dof">Source Code</a>
                                <p></p>
                                <p>
                                    Implementation of the paper <em>"Hand-Eye Calibration of SCARA Robots"</em> by M.
                                    Ulrich.
                                    Completed as part of an internship at <a href="https://www.vecnarobotics.com/">Vecna
                                    Robotics</a>.
                                <p></p>
                                </p>
                            </td>
                        </tr>

                        <tr>
                            <td style="padding-left:20px;width:10%;vertical-align:middle">
                                <!--                    <td style="padding:20px;width:25%;vertical-align:middle">-->
                                <div class="one">
                                    <img src='images/ros_openpose.gif' width="180">
                                </div>
                            </td>
                            <!--            <td style="padding-left:80px;padding-bottom:70px;width:90%;vertical-align:middle">-->
                            <td style="padding-left:80px;padding-bottom:70px;width:90%;vertical-align:middle">
                                <a href="https://github.com/ravijo/ros_openpose">
                                    <papertitle>ROS OpenPose</papertitle>
                                </a>
                                <br>
                                <em>GitHub Repository</em>, 2019
                                <br>
                                <a href="https://github.com/ravijo/ros_openpose">Source Code</a>
                                <p></p>
                                <p>
                                    ROS wrapper for OpenPose with support for key commercial cameras used by the
                                    robotics
                                    community.
                                </p>
                            </td>
                        </tr>

                        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                            <tbody>
                            <tr>
                                <td>
                                    <heading>Undergraduate Robotics Projects</heading>
                                </td>
                            </tr>
                            </tbody>
                        </table>
                        <table width="100%" align="center" border="0" cellpadding="20">
                            <tbody>

                            <tr>
                                <td style="padding-left:20px;width:10%;vertical-align:middle">
                                    <!--                    <td style="padding:20px;width:25%;vertical-align:middle">-->
                                    <div class="one">
                                        <img src='images/duke.gif' width="180">
                                    </div>
                                </td>
                                <td style="padding-left:80px;width:90%;vertical-align:middle">
                                    <a href="https://github.com/QuantuMope/duke-robodog">
                                        <papertitle>Duke: Voice Controlled Robot Dog</papertitle>
                                    </a>
                                    <br>
                                    <em>For Fun Project</em>, 2019
                                    <br>
                                    <a href="https://www.youtube.com/watch?v=mIvEY3RJ5Mg">Video</a>
                                    /
                                    <a href="https://github.com/QuantuMope/duke-robodog">CAD</a>
                                    <p></p>
                                    <p>
                                        An Arduino controlled robot dog that I created while healing from a knee
                                        surgery.
                                        Can do simple functionalities such as sit and respond to praise.
                                        So far, the YouTube video has amassed over 113000 views!
                                    <p></p>
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td style="padding-left:20px;width:10%;vertical-align:middle">
                                    <!--                    <td style="padding:20px;width:25%;vertical-align:middle">-->
                                    <div class="one">
                                        <img src='images/grimdor.gif' width="180">
                                    </div>
                                </td>
                                <td style="padding-left:80px;padding-bottom:70px;width:90%;vertical-align:middle">
                                    <a href="https://github.com/QuantuMope/grimdor-shoe-tying-robot">
                                        <papertitle>Grimdor: Underactuated Shot Tying Manipulator</papertitle>
                                    </a>
                                    <br>
                                    <em>Undergraduate Senior Design Project</em>, 2018
                                    <br>
                                    <a href="https://www.youtube.com/watch?v=erNi07dH5pw">Video</a>
                                    /
                                    <a href="https://github.com/QuantuMope/grimdor-shoe-tying-robot">CAD</a>
                                    /
                                    <a href="https://github.com/QuantuMope/grimdor-shoe-tying-robot/blob/master/shoe-tying-robot-press.txt">News
                                        Coverage</a>
                                    <p></p>
                                    <p>
                                        A manipulator capable of tying shoes.
                                        Built under the design constraints of using at most 2 motors and a $600 budget.
                                        Won a robotics competition against <a href="https://www.meijo-u.ac.jp/english/">Meijo
                                        University</a>, resulting in an all expense paid trip to Japan to present the
                                        robot.
                                        Was featured on several news outlets.
                                        So far, the YouTube video has amassed over 54000 views!
                                    </p>
                                </td>
                            </tr>


                        </table>
                        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                            <tbody>
                            <tr>
                                <td style="padding:0px">
                                    <br>
                                    <p style="text-align:right;font-size:18px;">
                                        Website source code from <a
                                            href="https://github.com/jonbarron/jonbarron_website">Jon
                                        Barron</a>.
                                    </p>
                                </td>
                            </tr>
                            </tbody>
                        </table>
        </td>
    </tr>
</table>
</body>

</html>